{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    \"\"\" Function to count number of parameters in a model. \"\"\"\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np\n",
    "\n",
    "# For reproducibility\n",
    "def seed_everything(seed):\n",
    "    \"\"\" Seeds all relevant random generators to the same value. \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    print('Manual seed changed successfully.')\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  Load Raw Data and Define Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(train_batch_size, test_batch_size):\n",
    "    \n",
    "    # Data in train set and test set are [im_tensor, label]. im_tensor size - 1x32x32 (gray scale, 32x32 pixels)\n",
    "    trainset = datasets.MNIST('../Datasets/', train=True, download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                               transforms.Resize((32, 32)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                               ]))\n",
    "\n",
    "    val_set_size = int(0.2 * len(trainset))\n",
    "    trainset, valset = torch.utils.data.random_split(trainset, [len(trainset) - val_set_size, val_set_size])\n",
    "\n",
    "    testset = datasets.MNIST('../Datasets', train=False,\n",
    "                              transform=transforms.Compose([\n",
    "                              transforms.Resize((32, 32)),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,))\n",
    "                              ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True)\n",
    "    val_loader   = torch.utils.data.DataLoader(valset,   batch_size=train_batch_size, shuffle=False)\n",
    "    test_loader  = torch.utils.data.DataLoader(testset,  batch_size=test_batch_size,  shuffle=False)\n",
    "\n",
    "    return trainset, train_loader, valset, val_loader, testset, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load train data\n",
    "train_batch_size = 64\n",
    "test_batch_size = 1000\n",
    "\n",
    "train_set, train_loader, val_set, val_loader, test_set, test_loader = load_data(train_batch_size, test_batch_size)\n",
    "\n",
    "print(f'data shape: train {len(train_set)}, val {len(val_set)}, test {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display some images\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(255 - train_set[i][0].squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.title(f\"Label {train_set[i][1]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_feat_maps, dropout_layer=0):\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_feat_maps = n_feat_maps\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feat_maps, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(n_feat_maps, n_feat_maps, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(n_feat_maps*5*5, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "        if dropout_layer == 1:\n",
    "            self.dropout = nn.Dropout(p=0.2)\n",
    "            self.dropout_layer = 1\n",
    "        else:\n",
    "            self.dropout_layer = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        if self.dropout_layer == 1:\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Working on: ', device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch, model):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct    = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss   = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        train_loss += criterion(output, target).data  # sum up batch loss\n",
    "        preds       = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct    += preds.eq(target.data.view_as(preds)).cpu().sum().item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    accuracy    = 100. * correct / len(train_loader.dataset)\n",
    "    \n",
    "    total_train_accuracy.append(accuracy)\n",
    "    total_train_loss.append(train_loss)\n",
    "\n",
    "\n",
    "def eval(model,pred_res=0):\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct  = 0\n",
    "\n",
    "    preds_vec = []\n",
    "    for data, target in tqdm(val_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output       = model(data)\n",
    "        val_loss    += criterion(output, target).data  # sum up batch loss\n",
    "        \n",
    "        preds    = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += preds.eq(target.data.view_as(preds)).cpu().sum().item()\n",
    "        preds_vec.append(preds.squeeze(1))\n",
    "        \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    accuracy  = 100. * correct / len(val_loader.dataset)\n",
    "    \n",
    "    total_val_accuracy.append(accuracy)\n",
    "    total_val_loss.append(val_loss)\n",
    "\n",
    "    print('\\nValidation set: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(val_loader.dataset),\n",
    "        accuracy))\n",
    "    \n",
    "    if pred_res == 1:\n",
    "        preds_vec = torch.hstack(preds_vec)\n",
    "        return preds_vec, accuracy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train and Evaluate a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define number of feature maps\n",
    "n_feat_maps = 3\n",
    "num_epoches = [5, 10, 15] # Define the number of epochs\n",
    "\n",
    "T_train_acc_no,  T_val_acc_no  = [], [] \n",
    "T_train_loss_no, T_val_loss_no = [], []\n",
    "models_comp_epoch = []\n",
    "\n",
    "for e in range(len(num_epoches)):\n",
    "    model_cnn        = CNN(n_feat_maps  )\n",
    "    model_cnn_w_drop = CNN(n_feat_maps,1)\n",
    "\n",
    "    models_comp = [model_cnn, model_cnn_w_drop]\n",
    "    models_comp_epoch.append(model_cnn)\n",
    "    models_comp_epoch.append(model_cnn_w_drop)\n",
    "    \n",
    "    print('\\033[1mNumber of Epochs: {}\\033[0m'.format(num_epoches[e]))\n",
    "    \n",
    "    for i in range(2):   \n",
    "        # Send Model to device and set the optimizer\n",
    "        models_comp[i].to(device)\n",
    "        optimizer = optim.SGD(models_comp[i].parameters(), lr=0.01, momentum=0.5)\n",
    "        print('Number of parameters: {}'.format(get_n_params(models_comp[i])))\n",
    "        \n",
    "        # Set count for accuracy and loss over epochs\n",
    "        total_train_accuracy, total_val_accuracy = [], []   # Initiating accuracy count\n",
    "        total_train_loss,     total_val_loss     = [], []   # Initiating loss count\n",
    "        \n",
    "        # Train and evaluate model\n",
    "        print('\\033[1mRun for model No. {}\\033[0m'.format(i))\n",
    "        for epoch in range(0, num_epoches[e]):\n",
    "            train(epoch, models_comp[i])\n",
    "            eval(models_comp[i])\n",
    "\n",
    "        # Set the count of accuracy and loss for the specific model\n",
    "        T_train_acc_no.append( total_train_accuracy)\n",
    "        T_val_acc_no.append(   total_val_accuracy  )  \n",
    "        T_train_loss_no.append(total_train_loss    )\n",
    "        T_val_loss_no.append(  total_val_loss      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\033[1mModel No. 0 - Without dropout layer\\nModel No. 1 - With dropout layer\\033[0m')\n",
    "\n",
    "for i in range(2*len(num_epoches)):\n",
    "    num_epoches_r = range(num_epoches[i//2])\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    ax[0].plot(num_epoches_r, T_train_acc_no[i], c='b', label='Train'     )\n",
    "    ax[0].plot(num_epoches_r, T_val_acc_no[i],   c='r', label='Validation')\n",
    "    ax[0].legend(loc='lower right')\n",
    "\n",
    "    ax[0].set_xlabel('Num_epochs') ; ax[0].set_ylabel('Accuracy [%]')\n",
    "    ax[0].title.set_text('Train - Validation Accuracy')\n",
    "\n",
    "    ax[0].grid() \n",
    "    ax[0].set_xticks(num_epoches_r)\n",
    "\n",
    "\n",
    "    ax[1].plot(num_epoches_r, T_train_loss_no[i], c='b', label='Train'     )\n",
    "    ax[1].plot(num_epoches_r, T_val_loss_no[i],   c='r', label='Validation')\n",
    "    ax[1].legend(loc='upper right')\n",
    "\n",
    "    ax[1].set_xlabel('Num_epochs') ; ax[1].set_ylabel('Loss')\n",
    "    ax[1].title.set_text('Train - Validation Loss')\n",
    "\n",
    "    ax[1].grid() \n",
    "    ax[1].set_xticks(num_epoches_r)\n",
    "\n",
    "    if i % 2  > 0:\n",
    "        md = 1\n",
    "    else:\n",
    "        md = 0\n",
    "    fig.suptitle('Train vs. Validation predictions results\\nModel No. {}\\n Number of epochs: {}'.format(md, num_epoches[i//2]), fontweight=\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct   = 0\n",
    "\n",
    "    preds_vec = []\n",
    "    for data, target in tqdm(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output       = model(data)\n",
    "        test_loss   += criterion(output, target).data  # sum up batch loss\n",
    "        \n",
    "        preds    = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += preds.eq(target.data.view_as(preds)).cpu().sum().item()\n",
    "        preds_vec.append(preds.squeeze(1))\n",
    "\n",
    "    test_loss    /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: loss: {:.4f}, accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_accuracy))\n",
    "\n",
    "    preds_vec = torch.hstack(preds_vec)\n",
    "    return preds_vec, test_accuracy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\033[1mModel No. 0 - Without dropout layer\\nModel No. 1 - With dropout layer\\033[0m')\n",
    "\n",
    "for indx in range(2*len(num_epoches)):\n",
    "    print('\\033[1mNumber of Epochs: {}\\033[0m'.format(num_epoches[indx//2]))\n",
    "    test_predictions, test_accuracy = test(models_comp_epoch[indx]  )\n",
    "    eval_predictions, eval_accuracy = eval(models_comp_epoch[indx],1)\n",
    "\n",
    "    test_true = test_set.targets\n",
    "\n",
    "    eval_true = []\n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        eval_true.append(target)\n",
    "    eval_true = torch.hstack(eval_true)\n",
    "\n",
    "    test_confmat = confusion_matrix(test_true, test_predictions)\n",
    "    eval_confmat = confusion_matrix(eval_true, eval_predictions)\n",
    "    df_cm_test = pd.DataFrame(test_confmat, index = [i for i in range(10)],\n",
    "                            columns = [i for i in range(10)])\n",
    "    df_cm_eval = pd.DataFrame(eval_confmat, index = [i for i in range(10)],\n",
    "                            columns = [i for i in range(10)])\n",
    "\n",
    "    if indx % 2  > 0:\n",
    "            md = 1\n",
    "    else:\n",
    "            md = 0\n",
    "\n",
    "    print('\\033[1mModel No. {}:\\033[0m'.format(md))\n",
    "    print('Test dataset accuracy: {}\\nValidation dataset accuracy: {}'.format(round(test_accuracy,3),round(eval_accuracy,3)))\n",
    "\n",
    "    f,(ax1,ax2) = plt.subplots(1,2)\n",
    "    f.set_figheight(5)\n",
    "    f.set_figwidth(15)\n",
    "\n",
    "    sn.heatmap(df_cm_test, annot=True, fmt='g', ax=ax1); ax1.set_title('Test dataset Confusion Matrix',      fontweight='bold')\n",
    "    sn.heatmap(df_cm_eval, annot=True, fmt='g', ax=ax2); ax2.set_title('Validation dataset Confusion Matrix',fontweight='bold')\n",
    "    f.suptitle('Test vs. Validation Confusion Matrices\\nModel No. {}\\n Number of epochs: {}'.format(md,num_epoches[indx//2]), fontweight=\"bold\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7d800ec1281210af2e9ff328fbdec3c68c6a0a400632e06fb16360d57c70088"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
